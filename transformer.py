# -*- coding: utf-8 -*-
"""DL_Ass2_(3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-KYVvI3qF0_KhuKoyFe2TRMvkzyH8IqT

**Introduction to Dataset**

The data has a total of 10 classes with 40 samples each. Make sure while working with the data, **esc10=True**. In the assignment, you are required to perform 4-fold validation. This dataset has been already divided into 5-folds. The column 'fold' in the metafile denotes the sample in a particular fold. Moreover, first folds is considered for test, rest for 4-fold validation.
"""

# DL Assignment 2
# Authors: Swati Shrivastava

# Installing the requirements
print('Installing Requirements... ',end='')
!pip install lightning
!pip install wandb # Install the wandb library
!pip install --upgrade torch torchvision torchaudio
!pip install --upgrade pytorch-lightning
print('Done')

# Importing Libraries
import os
from pathlib import Path
import pandas as pd
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
import torch
from google.colab import drive
import torch.nn as nn
import wandb
from sklearn.model_selection import KFold
import pytorch_lightning as pl
import torch.nn.functional as F

!wandb login 46ecee94bb3fac4079771ee3667889fa64ad1ba3

drive.mount('/content/drive')

# Specify the path to the zip file on Google Drive
data_zip_path = "/content/drive/MyDrive/DL_Assign2/Archive.zip"

# Specify the destination directory for extraction
extract_destination = "/content/drive/MyDrive/DL_Assign2/"

# Extract data
with zipfile.ZipFile(data_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_destination)

# Loading dataset
path = Path(extract_destination)
df = pd.read_csv(path / 'meta' / 'esc50.csv')

# Getting list of raw audio files
wavs = list(path.glob('audio/*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob

# Visualizing data
waveform, sample_rate = torchaudio.load(wavs[0])  # Load the waveform and sample rate of the first audio file using torchaudio

print("Shape of waveform: {}".format(waveform.size()))  # Print the shape of the waveform tensor
print("Sample rate of waveform: {}".format(sample_rate))  # Print the sample rate of the audio file

# Plot the waveform using matplotlib
plt.figure()
plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting

# Display the audio using IPython.display.Audio
ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform

# Define the Neural Network Architecture

class CustomNet(nn.Module):
    def __init__(self, num_classes=10):
        super(CustomNet, self).__init__()
        # 1D Convolution Layers
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, stride=1, padding=3)
        self.bn1 = nn.BatchNorm1d (16)
        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)
        self.bn2 = nn.BatchNorm1d (32)
        self.conv3 = nn.Conv1d (32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d (64)
        self.conv4 = nn.Conv1d (64, 48, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn. BatchNorm1d (48)

        self.fc1 = nn. Linear (8976, 128)
        self.fc2 = nn. Linear(128, num_classes)

        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = F.max_pool1d (F.relu(self.bn1(self.conv1(x))), 12)
        x = F.max_pool1d (F.relu(self.bn2(self.conv2(x))), 8)
        x = F.max_pool1d (F.relu (self.bn3 (self.conv3(x))), 4)
        x = F.max_pool1d (F.relu(self.bn4(self.conv4(x))), 2)

        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x)) # Add ReLU after fc1

        x = self.dropout(x)  # Apply dropout before the last fully connected layer
        x = self.fc2(x)
        return x

class CustomDataset(Dataset):
    def __init__(self, dataset, **kwargs):
        # Initialize CustomDataset object with relevant parameters
        # dataset: "train", "val", or "test"
        # kwargs: Additional parameters like data directory, dataframe, folds, etc.

        # Extract parameters from kwargs
        self.data_directory = kwargs["data_directory"]
        self.data_frame = kwargs["data_frame"]
        self.validation_fold = kwargs["validation_fold"]
        self.testing_fold = kwargs["testing_fold"]
        self.esc_10_flag = kwargs["esc_10_flag"]
        self.file_column = kwargs["file_column"]
        self.label_column = kwargs["label_column"]
        self.sampling_rate = kwargs["sampling_rate"]
        self.new_sampling_rate = kwargs["new_sampling_rate"]
        self.sample_length_seconds = kwargs["sample_length_seconds"]

        # Filter dataframe based on esc_10_flag and data_type
        if self.esc_10_flag:
            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]

        if dataset == "train":
            self.data_frame = self.data_frame.loc[
                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]
        elif dataset == "val":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]
        elif dataset == "test":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]

        # Get unique categories from the filtered dataframe
        self.categories = sorted(self.data_frame[self.label_column].unique())

        # Initialize lists to hold file names, labels, and folder numbers
        self.file_names = []
        self.labels = []

        # Initialize dictionaries for category-to-index and index-to-category mapping
        self.category_to_index = {}
        self.index_to_category = {}

        for i, category in enumerate(self.categories):
            self.category_to_index[category] = i
            self.index_to_category[i] = category

        # Populate file names and labels lists by iterating through the dataframe
        for ind in tqdm(range(len(self.data_frame))):
            row = self.data_frame.iloc[ind]
            file_path = self.data_directory / "audio" / row[self.file_column]
            self.file_names.append(file_path)
            self.labels.append(self.category_to_index[row[self.label_column]])

        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)

        # Window size for rolling window sample splits (unfold method)
        if self.sample_length_seconds == 2:
            self.window_size = self.new_sampling_rate * 2
            self.step_size = int(self.new_sampling_rate * 0.75)
        else:
            self.window_size = self.new_sampling_rate
            self.step_size = int(self.new_sampling_rate * 0.5)

    def get_num_classes(self):
        return len(self.categories)


    def __getitem__(self, index):
        # Split audio files with overlap, pass as stacked tensors tensor with a single label
        path = self.file_names[index]
        audio_file = torchaudio.load(path, format=None, normalize=True)
        audio_tensor = self.resampler(audio_file[0])
        splits = audio_tensor.unfold(1, self.window_size, self.step_size)
        samples = splits.permute(1, 0, 2)
        return samples, self.labels[index]

    def __len__(self):
        return len(self.file_names)

your_dataset = CustomDataset(dataset="train",
                             data_directory=path,
                             data_frame=df, validation_fold=1,
                             testing_fold=2, esc_10_flag=True,
                             file_column="filename",
                             label_column="category",
                             sampling_rate=44100,
                             new_sampling_rate=16000,
                             sample_length_seconds=1)

# Get the number of unique classes
num_classes = your_dataset.get_num_classes()
print("Number of classes:", num_classes)

class CustomDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        # Initialize the CustomDataModule with batch size, number of workers, and other parameters
        super().__init__()
        self.batch_size = kwargs["batch_size"]
        self.num_workers = kwargs["num_workers"]
        self.data_module_kwargs = kwargs

    def setup(self, stage=None):
        # Define datasets for training, validation, and testing during Lightning setup

        # If in 'fit' or None stage, create training and validation datasets
        if stage == 'fit' or stage is None:
            self.training_dataset = CustomDataset(dataset="train", **self.data_module_kwargs)
            self.validation_dataset = CustomDataset(dataset="val", **self.data_module_kwargs)

        # If in 'test' or None stage, create testing dataset
        if stage == 'test' or stage is None:
            self.testing_dataset = CustomDataset(dataset="test", **self.data_module_kwargs)

    def train_dataloader(self):
        # Return DataLoader for training dataset
        return DataLoader(self.training_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def val_dataloader(self):
        # Return DataLoader for validation dataset
        return DataLoader(self.validation_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Return DataLoader for testing dataset
        return DataLoader(self.testing_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        examples = torch.stack(examples)
        examples = examples.reshape(examples.size(0),1,-1)
        labels = torch.flatten(torch.tensor(labels))

        return [examples, labels]

# Data Setup
test_samp = 1 #Do not change this!!
valid_samp = 2 # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
batch_size = 16 # Free to change
num_workers = 8 # Free to change
custom_data_module = CustomDataModule(batch_size=batch_size,
                                      num_workers=num_workers,
                                      data_directory=path,
                                      data_frame=df,
                                      validation_fold=valid_samp,
                                      testing_fold=test_samp,  # set to 0 for no test set
                                      esc_10_flag=True,
                                      file_column='filename',
                                      label_column='category',
                                      sampling_rate=44100,
                                      new_sampling_rate=16000,  # new sample rate for input
                                      sample_length_seconds=1  # new length of input in seconds
                                      )

custom_data_module.setup()

# Data Exploration
print('Class Label: ', custom_data_module.training_dataset[0][1])  # this prints the class label
print('Shape of data sample tensor: ', custom_data_module.training_dataset[0][0].shape)  # this prints the shape of the sample (Frames, Channel, Features)

# Dataloader(s)
x = next(iter(custom_data_module.train_dataloader()))
y = next(iter(custom_data_module.val_dataloader()))
z = next(iter(custom_data_module.test_dataloader()))
print('Train Dataloader:')
print(x)
print('Validation Dataloader:')
print(y)
print('Test Dataloader:')
print(z)

# Define your LightningModule

def accuracyfn(y_pred, y_true):
        """
        Compute the accuracy given predicted and true labels.

        Args:
        - y_pred (torch.Tensor): Predicted labels from the model.
        - y_true (torch.Tensor): True labels.

        Returns:
        - accuracy (torch.Tensor): Accuracy value.
        """
        # Get predicted labels by selecting the index with maximum probability
        _, predicted = torch.max(y_pred, 1)

        # Compute accuracy
        correct = (predicted == y_true).sum().item()
        total = y_true.size(0)
        accuracy = correct / total

        return accuracy

class CustomModel(pl.LightningModule):
    def __init__(self, model):
        super(CustomModel, self).__init__()
        self.model = model
        self.loss_function = nn.CrossEntropyLoss()

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_pred = self.model(x)
        loss = self.loss_function(y_pred, y)

        # Log training loss and accuracy for each step
        self.log('train_loss', loss, prog_bar=True)
        acc = accuracyfn(y_pred, y)
        self.log('train_acc', acc, prog_bar=True)

        # Log to WandB
        #wandb.log({"train_loss_step": loss.item(), "train_acc_step": acc})

        return loss


    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_pred = self.model(x)
        loss = self.loss_function(y_pred, y)
        acc = accuracyfn(y_pred, y)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        # Log to WandB
        #wandb.log({"val_loss": loss.item(), "val_acc": acc})

    def test_step(self, batch, batch_idx):
        x, y = batch
        y_pred = self.model(x)
        loss = self.loss_function(y_pred, y)
        acc = accuracyfn(y_pred, y)
        result = {'test_loss': loss, 'test_acc': acc, 'y_pred': y_pred}
        # Log to WandB
        #wandb.log({"test_loss": loss.item(), "test_acc": acc})

        return result

    def configure_optimizers(self):
        return torch.optim.Adam(self.model.parameters(), lr=1e-3)

from pytorch_lightning.loggers import WandbLogger
# Initialize WandB logger
wandb.init(project="transformers", name="archi1")

# Initialize model, data module, and trainer
model = CustomNet(num_classes=10)
custom_model = CustomModel(model)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

def train_model(model, train_loader, val_loader, optimizer, criterion, epochs):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

        training_loss = running_loss / len(train_loader)
        training_accuracy = 100. * correct / total
        # Log training loss and accuracy to WandB
        wandb.log({'Training Loss': training_loss, 'Training Accuracy': training_accuracy})
        print(f'Epoch: {epoch + 1}, Training Loss: {training_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%')

        # Validation step
        validate_model(model, val_loader, criterion, device)

def validate_model(model, val_loader, criterion, device):
    model.eval()
    val_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in val_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            val_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    val_loss /= len(val_loader.dataset)
    validation_accuracy = 100. * correct / len(val_loader.dataset)
    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')


train_model(custom_model, custom_data_module.train_dataloader(), custom_data_module.val_dataloader(), optimizer, criterion, epochs=100)

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, roc_curve, auc
import numpy as np

# Assuming your test dataloader is already set up
test_dataloader = custom_data_module.test_dataloader()

# Set the model to evaluation mode
custom_model.eval()

# Initialize lists to store true labels and predicted probabilities
true_labels = []
predicted_probs = []

# Iterate through the test set
for batch in test_dataloader:
    x, y = batch
    with torch.no_grad():
        y_pred = custom_model.model(x)

    # Apply softmax to normalize the predicted probabilities
    y_pred_prob = F.softmax(y_pred, dim=1)

    true_labels.extend(y.cpu().numpy())
    predicted_probs.extend(y_pred_prob.cpu().numpy())

# Convert the lists to numpy arrays
true_labels = np.array(true_labels)
predicted_probs = np.array(predicted_probs)

# Calculate Accuracy
accuracy = accuracy_score(true_labels, np.argmax(predicted_probs, axis=1))
print(f"Accuracy: {accuracy * 100:.2f}%")

# Calculate Confusion Matrix
conf_matrix = confusion_matrix(true_labels, np.argmax(predicted_probs, axis=1))
print(f"Confusion Matrix:\n{conf_matrix}")

# Calculate F1-score
f1 = f1_score(true_labels, np.argmax(predicted_probs, axis=1), average='weighted')
print(f"F1-Score: {f1}")

# Calculate AUC-ROC
auc_roc = roc_auc_score(true_labels, predicted_probs, multi_class='ovr')
print(f"AUC-ROC: {auc_roc}")

n_classes = 10  # Number of classes
wandb.log({'roc': wandb.plot.roc_curve(true_labels, predicted_probs)})


wandb.finish()

total_params = sum(p.numel() for p in custom_model.parameters())
trainable_params = sum(p.numel() for p in custom_model.parameters() if p.requires_grad)

print(f"Total Parameters: {total_params}")
print(f"Trainable Parameters: {trainable_params}")

"""Transformer"""

class MultiHeadSelfAttention(nn.Module):
    def __init__(self, embed_size, heads):
        super(MultiHeadSelfAttention, self).__init__()
        self.embed_size = embed_size
        self.heads = heads
        self.head_dim = embed_size // heads

        assert (
            self.head_dim * heads == embed_size
        ), "Embedding size needs to be divisible by heads"

        self.values = nn.Linear(heads * self.head_dim, heads * self.head_dim, bias=False)
        self.keys = nn.Linear(heads * self.head_dim, heads * self.head_dim, bias=False)
        self.queries = nn.Linear(heads * self.head_dim, heads * self.head_dim, bias=False)
        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)

    def forward(self, value, key, query):
        N = query.shape[0]
        value_len, key_len, query_len = value.shape[1], key.shape[1], query.shape[1]


        values = self.values(value).view(N, value_len, self.heads, self.head_dim)
        keys = self.keys(key).view(N, key_len, self.heads, self.head_dim)
        queries = self.queries(query).view(N, query_len, self.heads, self.head_dim)


        # Attention mechanism directly in forward method
        energy = torch.einsum("nqhd,nkhd->nhqk", [queries, keys])
        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)

        out = torch.einsum("nhql,nlhd->nqhd", [attention, values]).reshape(
            N, query_len, self.heads * self.head_dim
        )



        out = self.fc_out(out)
        return out

class TransformerBlock(nn.Module):
    def __init__(self, embed_size, heads, dropout, forward_expansion):
        super(TransformerBlock, self).__init__()
        self.attention = MultiHeadSelfAttention(embed_size, heads)
        self.norm1 = nn.LayerNorm(embed_size)
        self.norm2 = nn.LayerNorm(embed_size)

        self.feed_forward = nn.Sequential(
            nn.Linear(embed_size, forward_expansion * embed_size),
            nn.ReLU(),
            nn.Linear(forward_expansion * embed_size, embed_size),
        )

        self.dropout = nn.Dropout(dropout)

    def forward(self, value, key, query):
        attention = self.attention(value, key, query)
        x = self.dropout(self.norm1(attention + query))
        forward = self.feed_forward(x)
        out = self.dropout(self.norm2(forward + x))
        return out

class CustomNetWithTransformer(nn.Module):
    def __init__(self, num_classes=10, num_heads=2, num_transformer_blocks=2):
        super(CustomNetWithTransformer, self).__init__()
        # Base Conv Layers
        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, stride=1, padding=3)
        self.bn1 = nn.BatchNorm1d(16)
        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2)
        self.bn2 = nn.BatchNorm1d(32)
        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm1d(64)
        self.conv4 = nn.Conv1d(64, 48, kernel_size=3, stride=1, padding=1)
        self.bn4 = nn.BatchNorm1d(48)

        # Transformer Blocks
        self.transformer_blocks = nn.ModuleList([
            TransformerBlock(embed_size=187, heads=num_heads, dropout=0.1, forward_expansion=4)
            for _ in range(num_transformer_blocks)
        ])

        self.fc1 = nn.Linear(8976, 128)  # Adjust input features based on transformer output
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        # Conv Layers
        x = F.max_pool1d(F.relu(self.bn1(self.conv1(x))), 12)
        x = F.max_pool1d(F.relu(self.bn2(self.conv2(x))), 8)
        x = F.max_pool1d(F.relu(self.bn3(self.conv3(x))), 4)
        x = F.max_pool1d(F.relu(self.bn4(self.conv4(x))), 2)

        # Transformer Blocks
        for transformer in self.transformer_blocks:
            x = transformer(x, x, x)

        x = x.view(x.size(0), -1)  # Flatten the output

        seq_length = 9
        head_dim = custom_data_module.training_dataset[0][0].shape[2]
        #print(x.shape)
        x = x.view(x.size(0),-1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        #x = F.softmax(x, dim=1)  # Apply softmax to output
        return x

class TransformerClassifier(nn.Module):
    def __init__(self, embed_size, num_layers, heads, device, forward_expansion, dropout, num_classes):
        super(TransformerClassifier, self).__init__()
        self.device = device
        self.transformer_blocks = nn.Sequential(
            *[TransformerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)]
        )
        self.out = nn.Linear(embed_size, num_classes)

    def forward(self, x):
        transformer_out = self.transformer_blocks(x, x, x)
        cls_token = transformer_out[:, 0, :]
        out = self.out(cls_token)
        return out

# Initialize WandB logger
wandb_logger = WandbLogger()

wandb.init(project="transformers", name="archi2_lat")

from torch.utils.data import DataLoader
import torch.optim as optim
import numpy as np

from pytorch_lightning.callbacks import Callback

# Assume train_loader is defined
model = CustomNetWithTransformer(num_classes=10, num_heads=1, num_transformer_blocks=2)
custom_model = CustomModel(model)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)




def train_model(model, train_loader, val_loader, optimizer, criterion, epochs):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

        training_loss = running_loss / len(train_loader)
        training_accuracy = 100. * correct / total
        # Log training loss and accuracy to WandB
        wandb.log({'Training Loss': training_loss, 'Training Accuracy': training_accuracy})
        print(f'Epoch: {epoch + 1}, Training Loss: {training_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%')

        # Validation step
        validate_model(model, val_loader, criterion, device)

def validate_model(model, val_loader, criterion, device):
    model.eval()
    val_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in val_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            val_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    val_loss /= len(val_loader.dataset)
    validation_accuracy = 100. * correct / len(val_loader.dataset)
    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')

# Assuming your model, optimizer, criterion, and custom_data_module are defined

train_model(model, custom_data_module.train_dataloader(), custom_data_module.val_dataloader(), optimizer, criterion, epochs=100)


test_dataloaderT = custom_data_module.test_dataloader()

# Set the model to evaluation mode
custom_model.eval()

# Initialize lists to store true labels and predicted probabilities
true_labelsT = []
predicted_probsT = []

# Iterate through the test set
for batch in test_dataloaderT:
    x, y = batch
    with torch.no_grad():
        y_pred = custom_model.model(x)

    # Apply softmax to normalize the predicted probabilities
    y_pred_prob = F.softmax(y_pred, dim=1)

    true_labelsT.extend(y.cpu().numpy())
    predicted_probsT.extend(y_pred_prob.cpu().numpy())

# Convert the lists to numpy arrays
true_labelsT = np.array(true_labelsT)
predicted_probsT = np.array(predicted_probsT)

# Calculate Accuracy
accuracy = accuracy_score(true_labelsT, np.argmax(predicted_probsT, axis=1))
print(f"Accuracy: {accuracy * 100:.2f}%")

# Calculate Confusion Matrix
conf_matrix = confusion_matrix(true_labelsT, np.argmax(predicted_probsT, axis=1))
print(f"Confusion Matrix:\n{conf_matrix}")

# Calculate F1-score
f1 = f1_score(true_labelsT, np.argmax(predicted_probsT, axis=1), average='weighted')
print(f"F1-Score: {f1}")

# Calculate AUC-ROC
auc_roc = roc_auc_score(true_labelsT, predicted_probsT, multi_class='ovr')
print(f"AUC-ROC: {auc_roc}")

n_classes = 10  # Number of classes
wandb.log({'roc for Transformers': wandb.plot.roc_curve(true_labelsT, predicted_probsT)})

wandb.finish()

total_params = sum(p.numel() for p in custom_model.parameters())
trainable_params = sum(p.numel() for p in custom_model.parameters() if p.requires_grad)

print(f"Total Parameters: {total_params}")
print(f"Trainable Parameters: {trainable_params}")

# Continue  for training the model for k fold for transformers

class CustomDataModuleKFoldT(pl.LightningDataModule):
    def __init__(self, k_folds, batch_size, num_workers, data_directory, data_frame, esc_10_flag, file_column, label_column, sampling_rate, new_sampling_rate, sample_length_seconds,validation_fold, testing_fold):
        super().__init__()
        self.k_folds = k_folds
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.data_directory = data_directory
        self.data_frame = data_frame
        self.esc_10_flag = esc_10_flag
        self.file_column = file_column
        self.label_column = label_column
        self.sampling_rate = sampling_rate
        self.new_sampling_rate = new_sampling_rate
        self.sample_length_seconds = sample_length_seconds
        self.validation_fold = validation_fold
        self.testing_fold = testing_fold

    def setup(self, stage=None):
        # Perform k-fold splitting and setup datasets
        kfold = KFold(n_splits=self.k_folds, shuffle=True, random_state=42)
        for fold, (train_idx, val_idx) in enumerate(kfold.split(self.data_frame, self.data_frame[self.label_column])):
            train_df, val_df = self.data_frame.iloc[train_idx], self.data_frame.iloc[val_idx]
            setattr(self, f'training_dataset_fold_{fold}', CustomDataset(dataset="train", data_frame=train_df,
                                                                        data_directory=self.data_directory,
                                                                        label_column=self.label_column,
                                                                        sampling_rate=self.sampling_rate,
                                                                        new_sampling_rate=self.new_sampling_rate,
                                                                        sample_length_seconds=self.sample_length_seconds,
                                                                        validation_fold=self.validation_fold,
                                                                        testing_fold=self.testing_fold,
                                                                        esc_10_flag=self.esc_10_flag, file_column=self.file_column))
            setattr(self, f'validation_dataset_fold_{fold}', CustomDataset(dataset="val", data_frame=val_df,
                                                                          data_directory=self.data_directory,
                                                                          label_column=self.label_column,
                                                                          sampling_rate=self.sampling_rate,
                                                                          new_sampling_rate=self.new_sampling_rate,
                                                                          sample_length_seconds=self.sample_length_seconds,
                                                                          validation_fold=self.validation_fold,
                                                                          testing_fold=self.testing_fold,
                                                                          esc_10_flag=self.esc_10_flag,
                                                                          file_column=self.file_column))

            # Create a separate testing dataset for each fold
            setattr(self, f'testing_dataset_fold_{fold}', CustomDataset(dataset="test", data_frame=val_df,  # Use val_df for testing in this case
                                                                       data_directory=self.data_directory,
                                                                       label_column=self.label_column,
                                                                       sampling_rate=self.sampling_rate,
                                                                       new_sampling_rate=self.new_sampling_rate,
                                                                       sample_length_seconds=self.sample_length_seconds,
                                                                       validation_fold=self.validation_fold,
                                                                       testing_fold=self.testing_fold,
                                                                       esc_10_flag=self.esc_10_flag,
                                                                       file_column=self.file_column))


    def train_dataloader(self):
        # Implement the DataLoader for the training dataset
        return DataLoader(getattr(self, f'training_dataset_fold_0'),  # Assuming using fold_0, modify accordingly
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Implement the DataLoader for the testing dataset
        return DataLoader(getattr(self, f'testing_dataset_fold_0'),  # Assuming using fold_0, modify accordingly
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        examples = torch.stack(examples)
        examples = examples.reshape(examples.size(0),1,-1)
        labels = torch.flatten(torch.tensor(labels))

        return [examples, labels]

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Function to evaluate the model on the test set and generate metrics
def evaluate_model(model, test_loader, device):
    model.eval()
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = torch.max(output, 1)
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())

    accuracy = accuracy_score(all_targets, all_predictions)
    f1 = f1_score(all_targets, all_predictions, average='weighted')
    auc_roc = roc_auc_score(all_targets, output.cpu().numpy(), multi_class='ovr')
    confusion_mat = confusion_matrix(all_targets, all_predictions)

    return accuracy, f1, auc_roc, confusion_mat

# Training and Validation Functions
def train_model(model, custom_data_module, epochs):
    trainer = pl.Trainer(max_epochs=epochs, log_every_n_steps=30, logger=wandb_logger)
    trainer.fit(model, custom_data_module)

# Create an instance of  CustomDataModule
for fold in range(4):
    data_module_kfoldT = CustomDataModuleKFoldT(batch_size=batch_size,
                                          num_workers=num_workers,
                                          data_directory=path,
                                          data_frame=df,
                                          esc_10_flag=True,
                                          file_column='filename',
                                          label_column='category',
                                          sampling_rate=44100,
                                          new_sampling_rate=16000,
                                          sample_length_seconds=1,
                                          validation_fold=fold+1,
                                          testing_fold=test_samp,
                                          k_folds=4)  # Change k_folds as needed

    data_module_kfoldT.setup()

    # Create an instance of your model
    modelkfldT = CustomNetWithTransformer(num_classes=10, num_heads=1, num_transformer_blocks=2)
    model = CustomModel(modelkfldT)

    # Train the model using PyTorch Lightning
    train_model(model, data_module_kfoldT, epochs=3)

    # Evaluate the model on the test set
    test_loader = DataLoader(data_module_kfoldT.testing_dataset_fold_0, batch_size=batch_size, num_workers=num_workers)
    accuracy, f1, auc_roc, confusion_mat = evaluate_model(model, test_loader, device="cuda" if torch.cuda.is_available() else "cpu")

    print(f"\nResults for Fold {fold+1}:\n")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"AUC-ROC: {auc_roc:.4f}")
    print("Confusion Matrix:\n", confusion_mat)

    wandb.log({'roc for Transformers k fold': wandb.plot.roc_curve(true_labelsT, predicted_probsT)})

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f'Total Parameters: {total_params}, Trainable Parameters: {trainable_params}')